<html>
  <!-- Any copyright is dedicated to the Public Domain.
			  http://creativecommons.org/publicdomain/zero/1.0/
	-->
	<head>
		<title>Reticle example</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<script src="../libs/three/three.min.js"></script>
		<script module src="../../xrshim.js"></script>
		<link rel="stylesheet" href="../common.css"/>
	</head>
	<body>
		<div id="description">
			<h2>Reticle</h2>
			<h5>(click to dismiss)</h5>
			<p>Place a reticle on surfaces.</p>
		</div>
		<button type=button id=go-button>Go</button>
		<script type=module>
			/*
			Reticle Example shows how to find surfaces or other features and place reticle relative to them.

			In a production application, you would likely want to request world geometry, rather than only 
			using low level hit testing, and fall back to this method if the user declines to provide 
			real world geometry access.
			*/

			// some dependencies and utilities
			import * as mat4 from '../libs/gl-matrix/mat4.js';
			import * as vec3 from '../libs/gl-matrix/vec3.js';

			import XREngine from '../XREngine.js';
			import XRInputManager from '../XRInputManager.js';

			let session = null;
			let localReferenceSpace = null;
			let viewerReferenceSpace = null;
			let engine = null;
			
			// temporary working variables
			const workingMatrix = mat4.create();
			const workingVec3 = vec3.create();

			let savedOrigin = [0,0,0];
			let savedDirection = [0,0,-1];
			const reticleParent = new THREE.Object3D();
			let reticle = null;
			
			const reticleTrackedColor = new THREE.Color(0xDDFFDD);
			const reticleNotTrackedColor = new THREE.Color(0xFF6666);
			const reticleMaterial = new THREE.MeshBasicMaterial({color: reticleTrackedColor});
			let requestNextHit = true;

			// handle hit testing slightly differently than other samples, since we're doing
			// it per frame.  The "boiler plate" code below is slightly different, setting 
			// requestNextHit on tap instead of executing the hit test.  The custom XREngineHits
			// does a hit test each frame if the previous one has resolved
			const handleHitResults = (hits, frame) => {
				const size = 0.05;
				if (hits.length > 0) {
					const hit = hits[0];

					// convert hit matrices from head to eye level coordinate systems
					mat4.copy(workingMatrix, frame.getPose(localReferenceSpace, viewerReferenceSpace).transform.matrix);
					mat4.multiply(workingMatrix, workingMatrix, hit.hitMatrix);

					reticleParent.matrix.fromArray(workingMatrix);
					reticleParent.visible = true;   // it starts invisible
					reticle.material.color = reticleTrackedColor;

					reticleParent.updateMatrixWorld(true);
				} else {
					reticle.material.color = reticleNotTrackedColor;
				}
				requestNextHit = true;
			};

			class XREngineHits extends XREngine {
				endFrame(frame) {
					if (requestNextHit) {
						requestNextHit = false;

						session.requestHitTest(savedDirection, viewerReferenceSpace, frame)
							.then(hits => handleHitResults(hits, frame))
							.catch(err => {
								console.error('Error testing hits', err);
							});
					}
				}
			}

			document.getElementById('description').addEventListener('touchstart', event => {
				event.target.style.display = 'none';
				event.stopPropagation();
			}, {capture: true});

			document.getElementById('go-button').addEventListener('click', event => {
				if (!session) {
					navigator.xr.isSessionSupported('immersive-ar').then(supported => {
						if (supported) {
							navigator.xr.requestSession('immersive-ar')
								.then(handleSessionStarted)
								.catch(err => {
									console.error('Session setup error', err);
								});
							document.getElementById('go-button').innerText = 'End';
							document.getElementById('go-button').style.display = 'none';
						} else {
							throw new Error('No immersive-ar support');
						}
					});
				} else {
					session.end();
					session = null;
					reticleParent.visible = false;   // it starts invisible
					document.getElementById('description').style.display = 'block';
					document.getElementById('go-button').style.display = 'block';
					document.getElementById('go-button').innerText = 'Go';
				}
			}, true);

			document.getElementById('go-button').addEventListener('touchstart', event => {
				event.stopPropagation()
			}, true);

			// handle input events from the XRInputManager
			const inputManager = new XRInputManager((eventName, details) => {
				if (session === null) return;

				switch(eventName){
					case 'normalized-touch':
						hitTestWithScreenCoordinates(...details.normalizedCoordinates);
						break;
					default:
						console.error('unknown xr input event', eventName, details);
						break;
				}
			});

			const hitTestWithScreenCoordinates = (normalizedX, normalizedY) => {
				// Convert the screen coordinates into head-model origin/direction for hit testing
				const [origin, direction] = XRInputManager.convertScreenCoordinatesToRay(
					normalizedX, normalizedY, engine.camera.projectionMatrix);
				savedOrigin = origin;
				savedDirection = direction;

				requestNextHit = true;
			};

			const handleSessionStarted = async xrSession => {
				session = xrSession;

				// Create the context where we will render our 3D scene
				const canvas = document.createElement('canvas');
				const context = canvas.getContext('webgl', {
					xrCompatible: true
				});

				if (!context) throw new Error('Could not create a webgl context');

				// Set up the base layer
				session.updateRenderState({baseLayer: new XRWebGLLayer(session, context)});

				localReferenceSpace = await session.requestReferenceSpace('local');
				viewerReferenceSpace = await session.requestReferenceSpace('viewer');

				// Create a simple test scene and renderer
				// The engine's scene is in the eye-level coordinate system 
				// Our custom engine class does hit testing at the end of each rAF 
				engine = new XREngineHits(canvas, context);

				session.requestAnimationFrame(async (t, frame) => {
					// get the location of the device, and use it to create an 
					// anchor with the identity orientation
					mat4.copy(workingMatrix, frame.getPose(localReferenceSpace, viewerReferenceSpace).transform.matrix);
					mat4.getTranslation(workingVec3, workingMatrix);
					mat4.fromTranslation(workingMatrix, workingVec3);

					const anchor = await session.addAnchor(workingMatrix, localReferenceSpace, frame);
					engine.addAnchoredNode(anchor, engine.root);

					// Kick off rendering
					session.requestAnimationFrame(handleAnimationFrame);
				});

				// initialize scene

				engine.addAmbientLight();
				engine.addDirectionalLight();

				// Add a box and axis at the origin of the eye-level coordinate system
				// for debugging by uncommenting these lines
				// engine.addBox([0, 0, 0], [0.025, 0.025, 0.025], 0x44ff44)
				// engine.addAxesHelper([0,0,0], [0.2,0.2,0.2])				
				
				reticle = new THREE.Mesh(
					new THREE.RingGeometry(0.04, 0.05, 36, 64),
					reticleMaterial
				);

				reticle.geometry.applyMatrix(new THREE.Matrix4().makeRotationX(THREE.Math.degToRad(-90)));
				reticleParent.add(reticle);

				reticleParent.matrixAutoUpdate = false;
				reticleParent.visible = false;
				engine.scene.add(reticleParent);
			};

			////////////////
			// render loop			
			const handleAnimationFrame = (t, frame) => {
				if (!session || session.ended) return;

				session.requestAnimationFrame(handleAnimationFrame);

				const pose = frame.getViewerPose(localReferenceSpace);
				if (!pose) {
					console.log('No pose');
					return;
				}

				engine.startFrame();
				for (const view of pose.views) {
					engine.preRender(
						session.renderState.baseLayer.getViewport(view),
						view.projectionMatrix,
						view.transform.inverse.matrix
					);
					engine.render();
				}
				engine.endFrame(frame);
			};
		</script>
	</body>
</html>